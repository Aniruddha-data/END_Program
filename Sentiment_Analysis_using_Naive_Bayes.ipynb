{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis using Naive Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aniruddha-data/END_Program/blob/main/Sentiment_Analysis_using_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4tgyjYGU5mh"
      },
      "source": [
        "# Sentiment Analysis using Naive Bayes\n",
        "\n",
        "In this assignment, we will attempt to label tweets with sentiments (positive, neutral and negative) using Naive Bayes classifier. Naive Bayes is a very basic approach to this problem, but gives surprisingly good accuracy sometimes.\n",
        "\n",
        "**Fill in the Blanks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af8UfnQOVXGZ"
      },
      "source": [
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91xo5PKAUoux"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEeXoKyvVqdQ"
      },
      "source": [
        "## Reading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "menn3WewVpe9",
        "outputId": "4b69b012-1138-4dee-f8ce-9eb58455d6be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data=pd.read_csv('tweets.csv')\n",
        "data.drop(data.columns[0],axis=1,inplace=True)\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUNORaDVwrN"
      },
      "source": [
        "## Text processing for the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCtQLFwcHauQ",
        "outputId": "64c0f16f-c66c-4fa5-cde2-b7fba7e42370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbVn9swJVuLA"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation \n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])\n",
        "    \n",
        "def processTweet(tweet):\n",
        "    # tweet is the text we will pass for preprocessing \n",
        "    # convert passed tweet to lower case \n",
        "    #--Fill--\n",
        "    tweet=tweet.lower()\n",
        "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
        "    tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
        "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
        "    \n",
        "    # use work_tokenize imported above to tokenize the tweet\n",
        "    #--Fill--\n",
        "    word_token = word_tokenize(tweet)\n",
        "    return [word for word in word_token if word not in stopwords]\n",
        "    #return [word for word in tweet]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm-KtAzuW_On"
      },
      "source": [
        "#data['tweets'] = data['tweets'].astype('string')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukD-LrByYLZ0",
        "outputId": "d055e8f5-cf20-4039-b1d0-df993c373a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweets    5\n",
              "labels    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW3DNlRKYXQ4"
      },
      "source": [
        "import numpy as np\n",
        "data = data.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3a9xzqDdMZE"
      },
      "source": [
        "#data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f60g3HIYb81",
        "outputId": "6eba9cf7-6f5d-4d1e-ed27-aedb73de0ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweets    0\n",
              "labels    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gk8veQrWK7J"
      },
      "source": [
        "## Process all tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44jBcZrTV1QQ"
      },
      "source": [
        "processed=[]\n",
        "\n",
        "for tweet in data['tweets']:\n",
        "    \n",
        "    # process all tweets using processTweet function above - store in variable 'cleaned' \n",
        "    cleaned=processTweet(tweet)\n",
        "    processed.append(' '.join(cleaned))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ_2PZV-WO_E"
      },
      "source": [
        "data['processed'] = processed"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjyR3i4AYe-F",
        "outputId": "3b89714c-925b-4712-b5a3-115df0053cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "      <td>obama called gop budget social darwinism nice ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "      <td>teen years obama known use marijuana cocaine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "      <td>ipa congratulates president barack obama leade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "      <td>rt whatsromneyhiding connection supporters cri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "      <td>rt obama approved targeted assassinations mode...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  ...                                          processed\n",
              "0  Obama has called the GOP budget social Darwini...  ...  obama called gop budget social darwinism nice ...\n",
              "1  In his teen years, Obama has been known to use...  ...       teen years obama known use marijuana cocaine\n",
              "2  IPA Congratulates President Barack Obama for L...  ...  ipa congratulates president barack obama leade...\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...  ...  rt whatsromneyhiding connection supporters cri...\n",
              "4  RT @wardollarshome: Obama has approved more ta...  ...  rt obama approved targeted assassinations mode...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JabmRdNiWUhc"
      },
      "source": [
        "## Create pipeline and define parameters for GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azZvCgLsWVaZ"
      },
      "source": [
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "\n",
        "tuned_parameters = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'clf__alpha': [1, 1e-1, 1e-2]\n",
        "}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0xeqceWWbz_"
      },
      "source": [
        "## Split data into test and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uznVuAUUWbPM"
      },
      "source": [
        "# split data into train and test with split as 0.2 \n",
        "X = data.processed\n",
        "y = data.labels\n",
        "\n",
        "#--Fill--\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1ZgcaM8WfRB"
      },
      "source": [
        "## Perform classification (using GridSearch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUwwb2IWWhmH",
        "outputId": "60d2dd0f-44e2-4d25-f148-fb57d81f6c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# perform GridSearch CV with 10 fold CV using pipeline and tuned_paramters defined above \n",
        "#clf = --Fill--\n",
        "from pprint import pprint\n",
        "from time import time\n",
        "import logging\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf= GridSearchCV(text_clf, tuned_parameters, \n",
        "                    cv=10,verbose=1)\n",
        "\n",
        "print(\"Performing grid search...\")\n",
        "print(\"pipeline:\", [name for name, _ in text_clf.steps])\n",
        "print(\"parameters:\")\n",
        "pprint(tuned_parameters)\n",
        "t0 = time()\n",
        "clf.fit(x_train, y_train)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print()\n",
        "\n",
        "print(\"Best score: %0.3f\" % clf.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = clf.best_estimator_.get_params()\n",
        "for param_name in sorted(tuned_parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "#clf.fit(x_train, y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['vect', 'tfidf', 'clf']\n",
            "parameters:\n",
            "{'clf__alpha': [1, 0.1, 0.01],\n",
            " 'tfidf__norm': ('l1', 'l2'),\n",
            " 'tfidf__use_idf': (True, False),\n",
            " 'vect__ngram_range': [(1, 1), (1, 2), (2, 2)]}\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 10.933s\n",
            "\n",
            "Best score: 0.840\n",
            "Best parameters set:\n",
            "\tclf__alpha: 0.1\n",
            "\ttfidf__norm: 'l2'\n",
            "\ttfidf__use_idf: False\n",
            "\tvect__ngram_range: (1, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   10.9s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE_mfhiUWyc8"
      },
      "source": [
        "## Classification report "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqvkzGFRWzIb",
        "outputId": "cbf1d56e-9e83-4cee-dfea-ead1be4e081d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# print classification report after predicting on test set with best model obtained in GridSearch\n",
        "#--Fill--\n",
        "\n",
        "# printing the optimal accuracy score and hyperparameters\n",
        "#print('We can get accuracy of',clf.best_score_,'using',clf.best_params_)\n",
        "\n",
        "# model with the best hyperparameters\n",
        "#nb = MultinomialNB(alpha=0.1)\n",
        "# predict\n",
        "predictions = clf.best_estimator_.predict(x_test)\n",
        "# evaluation metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.94      0.89       188\n",
            "           1       0.75      0.63      0.68        70\n",
            "           2       0.62      0.28      0.38        18\n",
            "\n",
            "    accuracy                           0.82       276\n",
            "   macro avg       0.74      0.61      0.65       276\n",
            "weighted avg       0.80      0.82      0.80       276\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0mmglta-aQD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcfHjVVW18-b",
        "outputId": "4b6e28b1-91b3-4993-f709-ec29116b5198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.best_estimator_.score(x_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9909420289855072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3LOMA3J2DX_",
        "outputId": "d9a8ccbd-ed9e-45b4-b4a5-73916f03aaff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.best_estimator_.score(x_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8152173913043478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shTpptLeW1SF"
      },
      "source": [
        "## Important:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdWycpFYW3iD",
        "outputId": "22f4a42f-9881-469b-bd46-1d057ce6efdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "counts = data.labels.value_counts()\n",
        "print(counts)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    947\n",
            "1    352\n",
            "2     81\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PQDsflL2UiG",
        "outputId": "37354c43-f53b-4ead-dc52-346e18785027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1380 entries, 0 to 1379\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   tweets     1380 non-null   object\n",
            " 1   labels     1380 non-null   int64 \n",
            " 2   processed  1380 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 32.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J03oHuVj4QAA",
        "outputId": "40d525ab-8a5e-4027-ad6f-444ec8307c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "print(\"Before OverSampling, counts of label '0': {}\".format(sum(y_train == 0))) \n",
        "print(\"Before OverSampling, counts of label '1': {} \\n\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '2': {} \\n\".format(sum(y_train == 2)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '0': 759\n",
            "Before OverSampling, counts of label '1': 282 \n",
            "\n",
            "Before OverSampling, counts of label '2': 63 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alXCeKMZ4kPo",
        "outputId": "f18b8239-1589-4e7e-82e2-aeee0a60fd3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Before OverSampling, counts of label '0': {}\".format(sum(y_test == 0))) \n",
        "print(\"Before OverSampling, counts of label '1': {} \\n\".format(sum(y_test == 1)))\n",
        "print(\"Before OverSampling, counts of label '2': {} \\n\".format(sum(y_test == 2)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before OverSampling, counts of label '0': 188\n",
            "Before OverSampling, counts of label '1': 70 \n",
            "\n",
            "Before OverSampling, counts of label '2': 18 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOFGFmVJ4pFy"
      },
      "source": [
        "# Class count\n",
        "count_class_0, count_class_1,count_class_2 = data.labels.value_counts()\n",
        "\n",
        "# Divide by class\n",
        "df_class_0 = data[data['labels'] == 0]\n",
        "df_class_1 = data[data['labels'] == 1]\n",
        "df_class_2 = data[data['labels'] == 2]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3vvJOta71y3",
        "outputId": "28f99b64-3eae-49ad-c6db-f614bda117eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
        "df_class_2_over = df_class_2.sample(count_class_0, replace=True)\n",
        "df_test_over = pd.concat([df_class_0, df_class_1_over,df_class_2_over], axis=0)\n",
        "\n",
        "print('Random over-sampling:')\n",
        "print(df_test_over.labels.value_counts())\n",
        "\n",
        "df_test_over.labels.value_counts().plot(kind='bar', title='Count (target)');"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random over-sampling:\n",
            "1    947\n",
            "2    947\n",
            "0    947\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kglimyQR-BMd"
      },
      "source": [
        "# split data into train and test with split as 0.2 \n",
        "X = df_test_over.processed\n",
        "y = df_test_over.labels\n",
        "\n",
        "#--Fill--\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itz8TIf7-UTi",
        "outputId": "c62e4071-c9d1-4e1d-b32e-ce7f856959b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# perform GridSearch CV with 10 fold CV using pipeline and tuned_paramters defined above \n",
        "#clf = --Fill--\n",
        "from pprint import pprint\n",
        "from time import time\n",
        "import logging\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf= GridSearchCV(text_clf, tuned_parameters, \n",
        "                    cv=10,verbose=1)\n",
        "\n",
        "print(\"Performing grid search...\")\n",
        "print(\"pipeline:\", [name for name, _ in text_clf.steps])\n",
        "print(\"parameters:\")\n",
        "pprint(tuned_parameters)\n",
        "t0 = time()\n",
        "clf.fit(x_train, y_train)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print()\n",
        "\n",
        "print(\"Best score: %0.3f\" % clf.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = clf.best_estimator_.get_params()\n",
        "for param_name in sorted(tuned_parameters.keys()):\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
        "#clf.fit(x_train, y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing grid search...\n",
            "pipeline: ['vect', 'tfidf', 'clf']\n",
            "parameters:\n",
            "{'clf__alpha': [1, 0.1, 0.01],\n",
            " 'tfidf__norm': ('l1', 'l2'),\n",
            " 'tfidf__use_idf': (True, False),\n",
            " 'vect__ngram_range': [(1, 1), (1, 2), (2, 2)]}\n",
            "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 17.827s\n",
            "\n",
            "Best score: 0.926\n",
            "Best parameters set:\n",
            "\tclf__alpha: 0.01\n",
            "\ttfidf__norm: 'l2'\n",
            "\ttfidf__use_idf: False\n",
            "\tvect__ngram_range: (1, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   17.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V3hBCl5-cIg",
        "outputId": "b9a300c0-c868-429e-adb4-eb6d73783580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# print classification report after predicting on test set with best model obtained in GridSearch\n",
        "#--Fill--\n",
        "\n",
        "# printing the optimal accuracy score and hyperparameters\n",
        "#print('We can get accuracy of',clf.best_score_,'using',clf.best_params_)\n",
        "\n",
        "# model with the best hyperparameters\n",
        "#nb = MultinomialNB(alpha=0.1)\n",
        "# predict\n",
        "predictions = clf.best_estimator_.predict(x_test)\n",
        "# evaluation metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.87      0.91       195\n",
            "           1       0.92      0.94      0.93       194\n",
            "           2       0.94      1.00      0.97       180\n",
            "\n",
            "    accuracy                           0.93       569\n",
            "   macro avg       0.94      0.94      0.94       569\n",
            "weighted avg       0.94      0.93      0.93       569\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C2haVHx-mk0",
        "outputId": "4aca7d8c-743d-42d6-fe8b-da1d1f9fbfc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(clf.best_estimator_.score(x_train, y_train))\n",
        "print(clf.best_estimator_.score(x_test, y_test))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9889964788732394\n",
            "0.9349736379613357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l3PcKXfW9LE"
      },
      "source": [
        "We can see above that the class distribution is highly imbalanced, this would not lead to good sampling of the data for the classifier. For your learning, try using [SMOTE](https://imbalanced-learn.readthedocs.io/en/stable/api.html) to oversample the minority classes and then evaluate the performance with Naive Bayes and compare."
      ]
    }
  ]
}